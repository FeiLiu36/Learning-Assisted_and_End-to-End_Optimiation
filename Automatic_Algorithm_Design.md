# Automatic Algorithm Design



## Books

+ [Combinatorial Optimization: Theory and Algorithms (Sixth Edition)](https://link.springer.com/book/10.1007%2F978-3-662-56039-6)
  + 基本信息：2019 Michel Gendreau, Jean-Yves Potvin
  + 摘要：Best known metaheuristics, more general issues on metaheuristics
  + 笔记：
+ [Handbook of Metaheuristics (Third Edition)](https://link.springer.com/book/10.1007/978-3-319-91086-4)
  + 基本信息：2018 Bernhard Korte, Jens Vygen, 
  + 摘要：The essential fundamentals of graph theory, linear and integer programming, and complexity theory. Some classical topics in CO
  + 笔记：
+ [Integer and Combinatorial Optimization](https://www.wiley.com/en-us/Integer+and+Combinatorial+Optimization-p-9780471359432)
  + 基本信息：Laurence A. Wolsey, George L. Nemhauser
  + 摘要：
  + 笔记：


# Course, textbooks and slides

+ [A course in combinatorial optimization](https://homepages.cwi.nl/~lex/files/dict.pdf)
  + 基本信息：Alexander Schrijver, SWI, Amsterdam, University of Amsterdam, Amsterdam, The Netherlands
  + 摘要：
  + 笔记：
+ [DM865 SDU - Heuristics and Approximation Algorithms](https://imada.sdu.dk/~marco/Teaching/AY2019-2020/DM865/)
  + 基本信息：Marco Chiarandini, University of Southern Denmark 
  + 摘要：
  + 笔记：
    + (Fei Liu 2021.10.11) 由组合优化问题引入, 介绍了启发式方法及其应用， 基础课程
+ [Discrete Optimization Coursera]( https://www.coursera.org/learn/discrete-optimization)
  + 基本信息：Coursera在线课程，Pascal Van Hentenryck, The University of Melbourne
  + 摘要：由背包问题引入，介绍了基本的动态规划，单纯形法，local search 等
  + 笔记：

## Lectures

+ [2020HUAWEI_Learning to optimize研讨会]

  录屏链接：https://pan.baidu.com/s/1b9bbJiLOhlT2y2vBQM6i-A 
  提取码：联系fliu36-c@my.cityu.edu.hk

  + 基本信息：2020.12.18

  + 摘要：

  + 笔记：

    张老师的观点：

    1。 启发式算法发展多年，虽理论薄弱，但是形成了一些合理且行之有效的算法设计原则，这些原则虽大多无十分严格的理论支撑，但容易理解可以解释。一些启发性算法换个角度也能解释成梯度法。现代一些learning to optimize 承deep learning 之威力，但有黑箱操作的感觉。如果能解决这个问题，对learning to optimize 的应用推广有力。如何增加解释性？

    2。一门学科成熟，大至要有基本概念、基本原理、基本方法 及应用。20年后大学对研究生能不能开一门learning to optimize 的课？这门课应该讲什么？我觉的对比其它学科可能会有启发，至少太复杂讲不清的东西不值得放到教材里。我觉的从这个角度展望未来对目前科研工作安排有利。我十分想向各位老师请教这一问题。

    3。learning to optimize 从数据中学习算法。经典算法设计用经验用问题先验知识设计算法，我个人觉得两者结合有很多可能工作，可能更有实用价值，比如算法参数配置问题可以model 成机器学习问题。理解两种方法的长短，对思考进一步工作有益。什么是这两个方法的本质优劣之处？如何互补？

    4。从复杂度理论看，概率意义下复杂性分析有可能对理解learn to optimize 有益。80年代有概率意义下的simplex method 算法分析，这些技术有无可能分析learn to optimize方法？需要从什么角度思考入手？

    5。 应用方面，周知问题建模重要，现在ai在建模方面能不能有些作为？

    万丈高楼平地起，我觉的不忘传统方法之优势，思考什么是可以做的，什么是不太可能的事情，思考如何利用当今ai 之成果推动启发性方法发展，铁树也许会开花。




